# -*- coding: utf-8 -*-
"""Copia de RetoMod2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZxbJUJgSSA_rfUbActI0-PjHkqqhYYCC
"""

from google.colab import drive

drive.mount("/content/gdrive")
!pwd  # show current path

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/gdrive/MyDrive/AI/Décimo/Reto Mod2/Birds"
!ls  # show current directory

# Librerías
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.utils import load_img
from tensorflow.keras.utils import img_to_array

# Se definen los directorios para cada dataset
train_dir ='/content/gdrive/MyDrive/AI/Décimo/Reto Mod2/Birds/train'
test_dir ='/content/gdrive/MyDrive/AI/Décimo/Reto Mod2/Birds/test'
valid_dir ='/content/gdrive/MyDrive/AI/Décimo/Reto Mod2/Birds/valid'

# Conjuntos de datos de imágenes
train_dataset = image_dataset_from_directory(
    train_dir,
    image_size=(224, 224),
    batch_size=32)

test_dataset = image_dataset_from_directory(
    test_dir,
    image_size=(224, 224),
    batch_size=32)

valid_dataset = image_dataset_from_directory(
    valid_dir,
    image_size=(224, 224),
    batch_size=32)

# Tamaño de imagen y tamaño de lote
image_size = (224, 224)
batch_size = 32

# Obtención los nombres de las clases del conjunto de datos de entrenamiento
class_names = train_dataset.class_names
np.shape(class_names)

# Visualización de algunas imágenes del conjunto de datos de entrenamiento
plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
      for i in range(12):
        ax = plt.subplot(4, 4, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i]])
        plt.axis("off")

# Definición de la secuencia de aumento de datos para diversificar el conjunto de datos de entrenamiento
data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.2),
        layers.RandomZoom(0.4),
    ]
)

# Visualización de las imágenes transformadas
plt.figure(figsize=(10, 10))
for images, _ in train_dataset.take(1):
    for i in range(9):
        augmented_images = data_augmentation(images)
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(augmented_images[0].numpy().astype("uint8"))
        plt.axis("off")

# Definición del tamaño de imagen
img_size = (224, 224)

# Modelo CNN con Keras
inputs = keras.Input(shape=(224, 224, 3))
x = data_augmentation(inputs)
x = layers.Rescaling(1./255)(inputs)

x = layers.BatchNormalization()(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2, padding="same")(x)

x = layers.BatchNormalization()(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2, padding="same")(x)

x = layers.BatchNormalization()(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2, padding="same")(x)

x = layers.BatchNormalization()(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2, padding="same")(x)

x = layers.BatchNormalization()(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.GlobalAveragePooling2D()(x)

x = layers.Dropout(0.6)(x)
x = layers.Flatten()(x)

outputs = layers.Dense(20, activation="softmax")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

# Información del modelo
model.summary()

# Compilación del modelo
model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

# Definición de los callbacks para guardar el mejor modelo durante el entrenamiento
callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="birds.keras",
        save_best_only=True,
        monitor="val_loss")]

# Entrenamiento del modelo
history = model.fit(
    train_dataset,
    epochs=20,
    validation_data = valid_dataset,
    callbacks=callbacks
)

# Se guarda el modelo
model.save('birds_model.h5')
model.save('birds.keras')

# Se carga el mejor modelo para probarlo con el dataset de test
test_model = keras.models.load_model("birds.keras")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.3f}")

# Se realizan predicciones sobre el conjunto de datos de prueba utilizando el modelo entrenado
pred = model.predict(test_dataset)
pred

# Clase predicha para la primera imagen en el conjunto de datos de prueba
np.argmax(pred[0])

# Función para mostrar los resultados de la predicción
def results(filename, class_names):
    img = load_img(filename, target_size=(224, 224))
    imgconv = img_to_array(img)
    img_array = np.expand_dims(imgconv, axis=0)
    pred = np.argmax(model.predict(img_array))
    predimg = class_names[pred]
    predver = np.max(model.predict(img_array))
    print(pred)
    plt.figure()
    plt.imshow(img)
    plt.title("Eto: {}, veroyatnost : {}".format(predimg, predver))
    plt.show()

results('/content/gdrive/MyDrive/AI/Décimo/Reto Mod2/Birds/test/MANDRIN DUCK/1.jpg', class_names)

# Se guarda el modelo
model.save('birds_model.h5')
model.save('birds.keras')

# Evaluación del modelo del dataset de validación
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]

# Graficación de los resultados
epochs = range(1, len(accuracy) + 1)

plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Valid accuracy")
plt.title("Training and Valid accuracy")
plt.legend()

plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Valid loss")
plt.title("Training and Valid loss")
plt.legend()

plt.show()